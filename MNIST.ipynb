{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.DataFrame(data = mnist['data'], columns = mnist['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target = pd.DataFrame(data = mnist['target'], columns = ['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data['Target'] = Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data = Data[:60000]\n",
    "Test_Data = Data[60001:]\n",
    "\n",
    "# Train_Data['kfold'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target_train = Target[:60000]\n",
    "Target_test = Target[60001:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def kfold(df,splits):\n",
    "#     df = df.sample(frac =1).reset_index(drop = True)\n",
    "#     # Define a Stratified K fold model \n",
    "#     kf = StratifiedKFold(n_splits = splits, shuffle=False, random_state=42)\n",
    "\n",
    "#     # Loop over all the fold indexes\n",
    "#     for fold, (train_idx, val_idx) in enumerate(kf.split(X = df, y = df.Target.values)):\n",
    "#         print(len(train_idx), len(val_idx), fold)\n",
    "#         # print(fold)\n",
    "#         # Change the \"kfold\" column values to their respetive fold numbers\n",
    "#         df.loc[val_idx, \"kfold\"] = fold\n",
    "#     # return the strafiedkfold file\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train_Data = kfold(Train_Data,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold = [0,1,2,3,4]\n",
    "# for f in fold:\n",
    "#     train_df = Train_Data[]\n",
    "\n",
    "# def train_test_split(Data, Target, Test_Size, Random_State):\n",
    "#     xtrain, xvalid, ytrain, yvalid = train_test_split(Data, Target, test_size = Test_Size, random_state = Random_State)\n",
    "#     return xtrain, xvalid, ytrain, yvalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    # '0' for get max values columnwise:\n",
    "    x_normed = x / x.max(0, keepdim=True)[0]\n",
    "    return x_normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data = np.array(Train_Data)\n",
    "Test_Data = np.array(Test_Data)\n",
    "Train_Data = Train_Data.astype(dtype = 'float64')\n",
    "Test_Data = Test_Data.astype(dtype = 'float64')\n",
    "Train_Data = torch.from_numpy(Train_Data)\n",
    "Test_Data = torch.from_numpy(Test_Data)\n",
    "# Train_Data_norm = normalize(Train_Data)\n",
    "# Test_Data_norm = normalize(Test_Data) \n",
    "# Train_Data_norm[torch.isnan(Train_Data_norm)] = 0\n",
    "# Test_Data_norm[torch.isnan(Test_Data_norm)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target_train = np.array(Target_train)\n",
    "Target_test = np.array(Target_test)\n",
    "Target_train = Target_train.astype(int)\n",
    "Target_test = Target_test.astype(int)\n",
    "Target_train = torch.from_numpy(Target_train)\n",
    "Target_test = torch.from_numpy(Target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc = OneHotEncoder()\n",
    "# Target_test = enc.fit_transform(Target_test)\n",
    "# Target_train = enc.fit_transform(Target_train)\n",
    "Target_test = torch.nn.functional.one_hot(Target_test)\n",
    "Target_train = torch.nn.functional.one_hot(Target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[0, 0, 1,  ..., 0, 0, 0],\n        [0, 1, 0,  ..., 0, 0, 0],\n        [1, 0, 0,  ..., 0, 0, 0],\n        ...,\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0],\n        [0, 0, 0,  ..., 0, 0, 0]])"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "Target_train.resize_(60000,10)\n",
    "Target_test.resize_(9999,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([9999, 784])"
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "Test_Data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Train_Data\n",
    "y = Target_train\n",
    "xPredicted = Test_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # Initilalize parameters:\n",
    "        self.inputsize = 784\n",
    "        self.outputsize = 10\n",
    "        # self.outputsize = 1\n",
    "        self.hiddensize = 255\n",
    "\n",
    "        #Weights\n",
    "        self.W1 = torch.randn(self.inputsize, self.hiddensize, dtype = torch.float64)\n",
    "        self.W2 = torch.randn(self.hiddensize, self.outputsize, dtype = torch.float64)\n",
    "\n",
    "        # self.W2 = torch.randn(self.hiddensize, self.hiddensize, dtype = torch.float64)\n",
    "        # self.W3 = torch.randn(self.hiddensize, self.outputsize, dtype = torch.float64)\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z = torch.matmul(X, self.W1)\n",
    "        self.z2 = self.sigmoid(self.z)\n",
    "        self.z3 = torch.matmul(self.z2, self.W2)\n",
    "        # self.z4 = self.sigmoid(self.z3)\n",
    "        # self.z5 = torch.matmul(self.z4, self.W3)\n",
    "        # o = self.relu(self.z5)\n",
    "        # print(self.z5.size())\n",
    "        o = self.sigmoid(self.z3)\n",
    "        return o\n",
    "\n",
    "    # def relu(self, x):\n",
    "    #     z = x.max(1, keepdim = True)[0]\n",
    "    #     return torch.tensor(z, dtype = torch.float64)\n",
    "\n",
    "    # def reluprime(self, x):\n",
    "    #     x[x>0] = 1\n",
    "    #     x[x<0] = 0\n",
    "    #     return x\n",
    "\n",
    "    \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + torch.exp(-s))\n",
    "\n",
    "    def sigmoidPrime(self, s):\n",
    "        # derivative of sigmoid\n",
    "        return s *(1-s)\n",
    "        # return self.sigmoid(s) * (1 - self.sigmoid(s))\n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        # print(o.size(),y.size())\n",
    "        # print(o,y)\n",
    "        self.o_error = y - o\n",
    "        # print(self.o_error)\n",
    "        # print(self.sigmoidPrime(o))\n",
    "        self.o_delta = self.o_error * self.sigmoidPrime(o)\n",
    "        # print(self.o_delta)\n",
    "        # self.o_delta = self.o_error * self.reluprime(o)\n",
    "        self.z2_error = torch.matmul(self.o_delta, torch.t(self.W2))\n",
    "        # print(self.z2_error)\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.z2)\n",
    "        # print(self.z2_delta)\n",
    "        # self.z3_error = torch.matmul(self.z2_delta, torch.t(self.W2))\n",
    "        # print(self.z3_error)\n",
    "        # self.z3_delta = self.z3_error * self.sigmoidPrime(self.z2)\n",
    "        # print(self.z3_delta)\n",
    "        self.W1 += torch.matmul(torch.t(X), self.z2_delta)\n",
    "        self.W2 += torch.matmul(torch.t(self.z2), self.o_delta)\n",
    "        # self.W3 += torch.matmul(torch.t(self.z3), self.o_delta)\n",
    "        print(\"weights\")\n",
    "        print(self.W1)\n",
    "        # self.W1 += torch.matmul(torch.t(X), self.z3_delta)\n",
    "        # self.W2 += torch.matmul(torch.t(self.z2), self.z2_delta)\n",
    "        # self.W3 += torch.matmul(torch.t(self.z3), self.o_delta)\n",
    "\n",
    "    def train(self,X,y):\n",
    "        o = self.forward(X)\n",
    "        self.backward(X,y,o)\n",
    "    \n",
    "    def saveWeights(self, model):\n",
    "        # we will use the PyTorch internal storage functions\n",
    "        torch.save(model, \"NN\")\n",
    "        # you can reload model with all the weights and so forth with:\n",
    "        # torch.load(\"NN\")\n",
    "\n",
    "    def predict(self):\n",
    "        print (\"Predicted data based on trained weights: \")\n",
    "        print (\"Input (scaled): \\n\" + str(xPredicted))\n",
    "        output = self.forward(xPredicted)\n",
    "        print (\"Output: \\n\" + str(output))\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "#0 Loss: 24.236135693039063\nweights\ntensor([[-0.3250, -0.5902, -0.0390,  ..., -0.7386,  0.5673, -0.0562],\n        [ 2.2707,  0.7966, -0.8493,  ...,  0.5128, -0.7668,  0.0459],\n        [-0.7067, -0.5483, -0.1746,  ..., -0.1492, -0.7241, -0.2063],\n        ...,\n        [-0.1483,  0.9439,  0.8487,  ..., -0.3792,  0.2696,  1.0657],\n        [-0.3258, -0.2393,  0.2355,  ...,  0.0541,  0.9762, -0.5477],\n        [ 0.5661, -0.5319,  1.2399,  ..., -0.3002,  1.3770,  0.4254]],\n       dtype=torch.float64)\n#1 Loss: 20.2774\nweights\ntensor([[-0.3250, -0.5902, -0.0390,  ..., -0.7386,  0.5673, -0.0562],\n        [ 2.2707,  0.7966, -0.8493,  ...,  0.5128, -0.7668,  0.0459],\n        [-0.7067, -0.5483, -0.1746,  ..., -0.1492, -0.7241, -0.2063],\n        ...,\n        [-0.1483,  0.9439,  0.8487,  ..., -0.3792,  0.2696,  1.0657],\n        [-0.3258, -0.2393,  0.2355,  ...,  0.0541,  0.9762, -0.5477],\n        [ 0.5661, -0.5319,  1.2399,  ..., -0.3002,  1.3770,  0.4254]],\n       dtype=torch.float64)\n#2 Loss: 20.2774\nweights\ntensor([[-0.3250, -0.5902, -0.0390,  ..., -0.7386,  0.5673, -0.0562],\n        [ 2.2707,  0.7966, -0.8493,  ...,  0.5128, -0.7668,  0.0459],\n        [-0.7067, -0.5483, -0.1746,  ..., -0.1492, -0.7241, -0.2063],\n        ...,\n        [-0.1483,  0.9439,  0.8487,  ..., -0.3792,  0.2696,  1.0657],\n        [-0.3258, -0.2393,  0.2355,  ...,  0.0541,  0.9762, -0.5477],\n        [ 0.5661, -0.5319,  1.2399,  ..., -0.3002,  1.3770,  0.4254]],\n       dtype=torch.float64)\n"
    }
   ],
   "source": [
    "NN = NeuralNetwork()\n",
    "for i in range(3):  # trains the NN 1,000 times\n",
    "    print (\"#\" + str(i) + \" Loss: \" + str(torch.mean((y - NN(X))**2).detach().item()))  # mean sum squared loss\n",
    "    NN.train(X, y)\n",
    "NN.saveWeights(NN)\n",
    "# y_pred = NN.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([9, 9, 9,  ..., 9, 9, 9])"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "torch.max(y_pred,1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=torch.float64)"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "y_pred[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitpytorchcondaec1204ad8b83441cb1c5886e0e9fd7ef",
   "display_name": "Python 3.7.7 64-bit ('pytorch': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}